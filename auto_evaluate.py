import requests, random, sys, time, traceback
from collections import defaultdict
from configparser import ConfigParser
from urllib.parse import urlparse, parse_qs
from auto_select import Auth
from bs4 import BeautifulSoup, Tag
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

def get_session_with_retries(session):
    retry_strategy = Retry(
        total=3,
        backoff_factor=1,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["HEAD", "GET", "OPTIONS", "POST"]
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    session.mount("http://", adapter)
    return session

def get_pending_evaluations(auth):
    BASE_URL = "https://jwxt.sztu.edu.cn"
    find_url = BASE_URL + "/jsxsd/xspj/xspj_find.do"
    
    try:
        res_find = auth.session.get(find_url, timeout=10)
        res_find.raise_for_status()
    except requests.exceptions.RequestException as e:
        print(f"è®¿é—®è¯„æ•™å…¥å£é¡µé¢å¤±è´¥: {e}")
        return []

    soup_find = BeautifulSoup(res_find.text, "html.parser")
    
    list_page_links = []
    for a in soup_find.find_all("a", href=True):
        if isinstance(a, Tag):
            href = a.get("href")
            if isinstance(href, str) and "xspj_list.do" in href:
                list_page_links.append(BASE_URL + href)

    all_tasks = []
    
    if list_page_links:
        print(f"å‘ç° {len(list_page_links)} ä¸ªè¯„æ•™ç±»åˆ«ï¼Œæ­£åœ¨é€ä¸ªæ£€æŸ¥...")
        for list_page_url in list_page_links:
            try:
                res_list = auth.session.get(list_page_url, timeout=10)
                res_list.raise_for_status()
                soup_list = BeautifulSoup(res_list.text, "html.parser")
                for a in soup_list.find_all("a", string="è¯„ä»·", href=True):
                    if isinstance(a, Tag):
                        href = a.get("href")
                        if isinstance(href, str) and "xspj_edit.do" in href:
                            task_url = BASE_URL + href
                            # å­˜å‚¨ä¸ºå…ƒç»„ (ç¼–è¾‘é¡µURL, æäº¤ç›®æ ‡URL)
                            all_tasks.append((task_url, list_page_url))
            except requests.exceptions.RequestException as e:
                print(f"è®¿é—®è¯„æ•™åˆ—è¡¨é¡µ {list_page_url} å¤±è´¥: {e}")
    else: # Fallback, unlikely to be used
        print("æœªå‘ç°è¯„æ•™ç±»åˆ«é¡µé¢ï¼Œå°è¯•ç›´æ¥æŸ¥æ‰¾è¯„æ•™ä»»åŠ¡...")
        # æ³¨æ„ï¼šæ­¤å›é€€é€»è¾‘æ— æ³•ç¡®å®šæ­£ç¡®çš„æäº¤ç›®æ ‡ï¼Œå¯èƒ½ä¼šå¤±è´¥
        submit_target_url = BASE_URL + "/jsxsd/xspj/xspj_save.do" 
        for a in soup_find.find_all("a", string="è¯„ä»·", href=True):
            if isinstance(a, Tag):
                href = a.get("href")
                if isinstance(href, str) and "xspj_edit.do" in href:
                    task_url = BASE_URL + href
                    all_tasks.append((task_url, submit_target_url))

    return all_tasks


def get_evaluate_form(auth, edit_url):
    res = auth.session.get(edit_url, timeout=10)
    soup = BeautifulSoup(res.text, "html.parser")
    form = soup.find("form")
    
    if not isinstance(form, Tag):
        print("æœªæ‰¾åˆ°è¯„æ•™è¡¨å•ï¼Œè·³è¿‡è¯¥ä»»åŠ¡ã€‚")
        return None

    payload = []
    radio_groups = {}
    
    all_tags = form.find_all(['input', 'textarea', 'select'])

    for tag in all_tags:
        if not isinstance(tag, Tag): continue
        name = tag.get('name')
        if not name: continue
        
        if tag.name == 'input' and tag.get('type') == 'radio':
            if name not in radio_groups:
                radio_groups[name] = []
            radio_groups[name].append(tag)
            continue

        value = ''
        if tag.name == 'select':
            options = [o for o in tag.find_all("option") if isinstance(o, Tag)]
            valid_options = []
            for o in options:
                val = o.get("value")
                if isinstance(val, str) and val.strip():
                    valid_options.append(o)
            
            if valid_options:
                is_score = True
                for o in valid_options:
                    val = o.get("value")
                    if not (isinstance(val, str) and val.replace('.', '', 1).isdigit()):
                        is_score = False
                        break

                if is_score:
                    scores = [o.get("value") for o in valid_options if isinstance(o.get("value"), str)]
                    weights = [i + 1 for i in range(len(scores))]
                    value = random.choices(scores, weights=weights, k=1)[0]
                else:
                    random_option = random.choice(valid_options)
                    value = random_option.get("value", "")
        elif tag.name == 'textarea':
            value = tag.text or "è€å¸ˆè®²è¯¾è®¤çœŸï¼Œå†…å®¹å……å®ï¼Œæ”¶è·å¾ˆå¤§ï¼"
        elif tag.name == 'input':
            if tag.get('type') == 'checkbox':
                if tag.has_attr('checked'):
                    value = tag.get('value', 'on')
            else:
                value = tag.get('value', '')
        
        payload.append((name, value))

    for name, radios in radio_groups.items():
        if radios:
            chosen_radio = random.choice(radios)
            payload.append((name, chosen_radio.get('value', '')))
    
    # Explicitly add the "save" button's data to the payload.
    # This is what tells the server we are saving, not submitting.
    payload.append(("zancun", "æš‚å­˜"))

    # URLå‚æ•°è¡¥å……ï¼Œä»¥é˜²ä¸‡ä¸€
    current_payload_keys = {item[0] for item in payload}
    parsed_url = urlparse(edit_url)
    query_params = parse_qs(parsed_url.query)
    for key, values in query_params.items():
        if key not in current_payload_keys:
            for v in values:
                payload.append((key, v))

    return payload

def submit_evaluation(auth, payload, submit_url, referer_url):
    BASE_URL = "https://jwxt.sztu.edu.cn"
    headers = {
        "Referer": referer_url,
        "User-Agent": "Mozilla/5.0",
        "Origin": BASE_URL,
        "Content-Type": "application/x-www-form-urlencoded",
    }
    resp = auth.session.post(submit_url, data=payload, headers=headers, timeout=15)
    return resp.text

def submit_final_evaluation(auth, list_page_url, num_tasks_in_list):
    """Performs the final 'Submit' action for a list of evaluations."""
    print(f"\n--- æ­£åœ¨å¯¹ç±»åˆ« {list_page_url.split('?')[0]} è¿›è¡Œæœ€ç»ˆæäº¤ ---")
    try:
        res = auth.session.get(list_page_url, timeout=10)
        res.raise_for_status()
        soup = BeautifulSoup(res.text, "html.parser")
        
        form = soup.find("form")
        if not isinstance(form, Tag):
            print("è­¦å‘Š: åœ¨åˆ—è¡¨é¡µé¢ä¸Šæœªæ‰¾åˆ°æœ€ç»ˆæäº¤çš„è¡¨å•ï¼Œè·³è¿‡æœ€ç»ˆæäº¤ã€‚")
            return
            
        payload = []
        # From the form on the list page, collect all input fields
        for tag in form.find_all("input"):
            if not isinstance(tag, Tag):
                continue
            name = tag.get("name")
            value = tag.get("value", "")
            # Collect all inputs with a 'name' attribute
            if name:
                payload.append((name, value))

        # Add the 'issavestr' parameter for each saved task. The value is 'æ˜¯' (Yes).
        for _ in range(num_tasks_in_list):
            payload.append(("issavestr", "æ˜¯"))
            
        # The correct target URL for the final submission, from captured network data.
        FINAL_SUBMIT_URL = "https://jwxt.sztu.edu.cn/jsxsd/xspj/xspj_All_submit.do"
        
        print("...å‘é€æœ€ç»ˆæäº¤è¯·æ±‚...")
        # Use the generic submit function, as the headers and process are similar
        result = submit_evaluation(auth, payload, submit_url=FINAL_SUBMIT_URL, referer_url=list_page_url)
        
        if "æäº¤æˆåŠŸ" in result:
            print("âœ… æœ€ç»ˆæäº¤æˆåŠŸï¼")
        else:
            print(f"âš ï¸ æœ€ç»ˆæäº¤å¯èƒ½å¤±è´¥ï¼ŒæœåŠ¡å™¨å“åº”: {result[:150].strip()}...")

    except requests.exceptions.RequestException as e:
        print(f"æœ€ç»ˆæäº¤æ—¶å‘ç”Ÿç½‘ç»œé”™è¯¯: {e}")


if __name__ == "__main__":
    try:
        conf = ConfigParser()
        conf.read("config.txt", encoding='utf-8')
        user = conf.get('mysql', 'username')
        pwd = conf.get('mysql', 'password')
        
        print("ğŸš€ å¼€å§‹è‡ªåŠ¨è¯„æ•™...")
        a = Auth()
        a.session = get_session_with_retries(a.session)

        if not a.login(user, pwd):
            print("âŒ ç™»å½•å¤±è´¥ï¼Œè¯·æ£€æŸ¥è´¦å·å¯†ç æˆ–ç½‘ç»œè¿æ¥ã€‚")
            sys.exit(1)
            
        print("âœ… ç™»å½•æˆåŠŸï¼Œæ­£åœ¨è·å–å¾…è¯„æ•™åˆ—è¡¨...")
        tasks = get_pending_evaluations(a)
        
        # Group tasks by their list_page_url to handle different evaluation categories
        tasks_by_list_page = defaultdict(list)
        for edit_url, list_page_url in tasks:
            tasks_by_list_page[list_page_url].append(edit_url)

        if not tasks_by_list_page:
            print("ğŸ‰ æœªå‘ç°å¾…è¯„æ•™ä»»åŠ¡ï¼Œæˆ–æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆã€‚")
            sys.exit(0)
            
        total_groups = len(tasks_by_list_page)
        print(f"ğŸ” å…±å‘ç° {len(tasks)} ä¸ªå¾…è¯„æ•™ä»»åŠ¡ï¼Œåˆ†å¸ƒåœ¨ {total_groups} ä¸ªç±»åˆ«ä¸­ã€‚")

        # Process each group of tasks
        for i, (list_page_url, edit_urls) in enumerate(tasks_by_list_page.items(), 1):
            num_tasks_in_group = len(edit_urls)
            print(f"\n--- æ­£åœ¨å¤„ç†ç¬¬ {i}/{total_groups} ä¸ªè¯„æ•™ç±»åˆ« ({num_tasks_in_group} ä¸ªä»»åŠ¡) ---")

            # 1. Loop through all tasks in the group and "save" them
            for idx, edit_url in enumerate(edit_urls, 1):
                print(f"\nâ¡ï¸ æ­£åœ¨ä¿å­˜ç¬¬ {idx}/{num_tasks_in_group} ä¸ªä»»åŠ¡ (ç±»åˆ« {i}/{total_groups})...")
                try:
                    payload = get_evaluate_form(a, edit_url)
                    
                    if not payload:
                        print("è¡¨å•é‡‡é›†å¤±è´¥ï¼Œè·³è¿‡ã€‚")
                        continue
                        
                    time.sleep(random.uniform(2, 5))
                    
                    save_url = "https://jwxt.sztu.edu.cn/jsxsd/xspj/xspj_save.do"
                    result = submit_evaluation(a, payload, submit_url=save_url, referer_url=edit_url)
                    
                    if "ä¿å­˜æˆåŠŸ" in result:
                        print(f"âœ… ä¿å­˜æˆåŠŸ!")
                    else:
                        print(f"âš ï¸ ä¿å­˜å¤±è´¥ã€‚æœåŠ¡å™¨å“åº”:")
                        print("--- BEGIN SERVER RESPONSE ---")
                        print(result)
                        print("--- END SERVER RESPONSE ---")

                except requests.exceptions.RequestException as e:
                    print(f"å¤„ç†ä¿å­˜ä»»åŠ¡æ—¶å‘ç”Ÿç½‘ç»œé”™è¯¯: {e}")
                    print("ç­‰å¾…5ç§’åç»§ç»­...")
                    time.sleep(5)

            # 2. After all tasks in the group are saved, perform the final submit for this group
            print(f"\n--- ç±»åˆ« {i} çš„æ‰€æœ‰ä»»åŠ¡å·²æš‚å­˜å®Œæ¯•ï¼Œæ­£åœ¨è¿›è¡Œæœ€ç»ˆæäº¤ ---")
            submit_final_evaluation(a, list_page_url, num_tasks_in_group)
                 
        print("\nğŸ‰ å…¨éƒ¨è¯„æ•™ä»»åŠ¡å¤„ç†å®Œæ¯•ï¼")
    except Exception as e:
        print(f"\nğŸ’¥ å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        traceback.print_exc()